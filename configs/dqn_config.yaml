algo: DQN
env: CartPole-v0
lr: 1e-2
n_episodes: 10000
hidden_sizes: [32]
epsilon_decay: 0.98
batch_size: 32
render: True
device: cuda:0
discount_factor: 0.99
target_update_step: 10000
trained_model_path: ./algorithms/trained_models/my_dqn.pth
test: False
replay_mem_size: 500000
learning_starts: 50000
learning_freq: 4
