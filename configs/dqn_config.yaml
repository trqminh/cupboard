algo: DQN
env: CartPole-v0
lr: 1e-2
n_episodes: 2200
hidden_sizes: [32]
ep_thresh: 0.1
batch_size: 128
render: True
device: cuda:0
discount_factor: 0.999
target_update_step: 2000
trained_model_path: ./algorithms/trained_models/my_dqn.pth
test: False
replay_mem_size: 50000
