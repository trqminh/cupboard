algo: DDPG
env: LunarLanderContinuous-v2
lr: 1e-2
hidden_sizes: [256, 256]
critic_hidden_size: 256
batch_size: 100
render: False
device: cuda:1
discount_factor: 0.99
update_every: 50
update_after: 1000
max_episode_len: 1000
steps_per_epoch: 4000
n_epochs: 100
polyak: 0.995
trained_model_path: ./algorithms/trained_models/my_ddpg_lunar.pth
test: False
memory_size: 1000000
start_steps: 100000
